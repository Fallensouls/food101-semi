                                                                                                                                                                                         ➜  food101-semi git:(main) ✗ python train.py --dataset uecfood100 --num-labeled 4000 --arch wideresnet --batch-size 48 --lr 0.06 --out results/uecfood100@0.2a --per-labeled 0.2

/usr/local/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/usr/local/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/usr/local/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/usr/local/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/usr/local/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/usr/local/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
11/10/2020 13:19:07 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False
11/10/2020 13:19:07 - INFO - __main__ -   {'T': 1, 'amp': False, 'arch': 'wideresnet', 'batch_size': 48, 'dataset': 'uecfood100', 'device': device(type='cuda', index=0), 'ema_decay': 0.999, 'eval_steps': 1024, 'gpu_id': 0, 'k_img': 65536, 'lambda_u': 1, 'local_rank': -1, 'lr': 0.06, 'mu': 4, 'n_gpu': 1, 'nesterov': True, 'no_progress': False, 'num_labeled': 4000, 'num_workers': 4, 'opt_level': 'O1', 'out': 'results/uecfood100@0.2a', 'per_labeled': 0.2, 'resume': '', 'seed': 5, 'start_epoch': 0, 'threshold': 0.95, 'total_steps': 262144, 'use_ema': True, 'warmup': 0, 'wdecay': 0.0005, 'world_size': 1}
11/10/2020 13:19:07 - INFO - dataset.cifar -   Dataset: UECFOOD
11/10/2020 13:19:07 - INFO - models.wideresnet -   Model: WideResNet 28x2
11/10/2020 13:19:07 - INFO - __main__ -   Total params: 1.51M
11/10/2020 13:19:09 - INFO - __main__ -   ***** Running training *****
11/10/2020 13:19:09 - INFO - __main__ -     Task = uecfood100@4000
11/10/2020 13:19:09 - INFO - __main__ -     Num Epochs = 256
11/10/2020 13:19:09 - INFO - __main__ -     Batch size per GPU = 48
11/10/2020 13:19:09 - INFO - __main__ -     Total train batch size = 48
11/10/2020 13:19:09 - INFO - __main__ -     Total optimization steps = 262144
WideResNet(
  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (block1): NetworkBlock(
    (layer): Sequential(
      (0): BasicBlock(
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)
        (relu1): LeakyReLU(negative_slope=0.1, inplace=True)
        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)
        (relu2): LeakyReLU(negative_slope=0.1, inplace=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (convShortcut): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (1): BasicBlock(
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)
        (relu1): LeakyReLU(negative_slope=0.1, inplace=True)
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)
        (relu2): LeakyReLU(negative_slope=0.1, inplace=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (2): BasicBlock(
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)
        (relu1): LeakyReLU(negative_slope=0.1, inplace=True)
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)
        (relu2): LeakyReLU(negative_slope=0.1, inplace=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (3): BasicBlock(
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)
        (relu1): LeakyReLU(negative_slope=0.1, inplace=True)
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)
        (relu2): LeakyReLU(negative_slope=0.1, inplace=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
  )
  (block2): NetworkBlock(
    (layer): Sequential(
      (0): BasicBlock(
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)
        (relu1): LeakyReLU(negative_slope=0.1, inplace=True)
        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)
        (relu2): LeakyReLU(negative_slope=0.1, inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (convShortcut): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (1): BasicBlock(
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)
        (relu1): LeakyReLU(negative_slope=0.1, inplace=True)
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)
        (relu2): LeakyReLU(negative_slope=0.1, inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (2): BasicBlock(
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)
        (relu1): LeakyReLU(negative_slope=0.1, inplace=True)
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)
        (relu2): LeakyReLU(negative_slope=0.1, inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (3): BasicBlock(
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)
        (relu1): LeakyReLU(negative_slope=0.1, inplace=True)
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)
        (relu2): LeakyReLU(negative_slope=0.1, inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
  )
  (block3): NetworkBlock(
    (layer): Sequential(
      (0): BasicBlock(
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)
        (relu1): LeakyReLU(negative_slope=0.1, inplace=True)
        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)
        (relu2): LeakyReLU(negative_slope=0.1, inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (convShortcut): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (1): BasicBlock(
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)
        (relu1): LeakyReLU(negative_slope=0.1, inplace=True)
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)
        (relu2): LeakyReLU(negative_slope=0.1, inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (2): BasicBlock(
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)
        (relu1): LeakyReLU(negative_slope=0.1, inplace=True)
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)
        (relu2): LeakyReLU(negative_slope=0.1, inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (3): BasicBlock(
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)
        (relu1): LeakyReLU(negative_slope=0.1, inplace=True)
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)
        (relu2): LeakyReLU(negative_slope=0.1, inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
  )
  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)
  (relu): LeakyReLU(negative_slope=0.1, inplace=True)
  (fc): Linear(in_features=128, out_features=100, bias=True)
  (l1): Linear(in_features=128, out_features=128, bias=True)
  (l2): Linear(in_features=128, out_features=128, bias=True)
)
Train Epoch: 1/ 256. Iter: 1024/1024. LR: 0.0600. Loss: 3.1315. Loss_x: 3.1281. Loss_u: 0.0035. Mask: 0.02. : 100%|██████████████████████████████████████| 1024/1024 [10:37<00:00,  1.61it/s]
Test Iter:   60/  60. Data: 0.019s. Batch: 0.041s. Loss: 4.3013. top1: 9.41. top5: 21.26. : 100%|████████████████████████████████████████████████████████████| 60/60 [00:02<00:00, 24.03it/s]
11/10/2020 13:29:49 - INFO - __main__ -   top-1 acc: 9.41
11/10/2020 13:29:49 - INFO - __main__ -   top-5 acc: 21.26
11/10/2020 13:29:49 - INFO - __main__ -   Best top-1 acc: 9.41
11/10/2020 13:29:49 - INFO - __main__ -   Mean top-1 acc: 9.41

Train Epoch: 2/ 256. Iter: 1024/1024. LR: 0.0600. Loss: 2.4664. Loss_x: 2.4481. Loss_u: 0.0183. Mask: 0.09. : 100%|██████████████████████████████████████| 1024/1024 [10:32<00:00,  1.62it/s]
Test Iter:   60/  60. Data: 0.014s. Batch: 0.036s. Loss: 3.5668. top1: 17.84. top5: 39.88. : 100%|███████████████████████████████████████████████████████████| 60/60 [00:02<00:00, 27.51it/s]
11/10/2020 13:40:23 - INFO - __main__ -   top-1 acc: 17.84
11/10/2020 13:40:23 - INFO - __main__ -   top-5 acc: 39.88
11/10/2020 13:40:23 - INFO - __main__ -   Best top-1 acc: 17.84
11/10/2020 13:40:23 - INFO - __main__ -   Mean top-1 acc: 13.63

Train Epoch: 3/ 256. Iter: 1024/1024. LR: 0.0600. Loss: 1.9908. Loss_x: 1.9451. Loss_u: 0.0457. Mask: 0.16. : 100%|██████████████████████████████████████| 1024/1024 [10:09<00:00,  1.68it/s]
Test Iter:   60/  60. Data: 0.014s. Batch: 0.036s. Loss: 2.8134. top1: 32.09. top5: 61.88. : 100%|███████████████████████████████████████████████████████████| 60/60 [00:02<00:00, 27.68it/s]
11/10/2020 13:50:35 - INFO - __main__ -   top-1 acc: 32.09
11/10/2020 13:50:35 - INFO - __main__ -   top-5 acc: 61.88
11/10/2020 13:50:35 - INFO - __main__ -   Best top-1 acc: 32.09
11/10/2020 13:50:35 - INFO - __main__ -   Mean top-1 acc: 19.78

Train Epoch: 4/ 256. Iter: 1024/1024. LR: 0.0600. Loss: 1.6629. Loss_x: 1.5884. Loss_u: 0.0746. Mask: 0.23. : 100%|██████████████████████████████████████| 1024/1024 [10:13<00:00,  1.67it/s]
Test Iter:   60/  60. Data: 0.016s. Batch: 0.038s. Loss: 2.5539. top1: 42.10. top5: 71.16. : 100%|███████████████████████████████████████████████████████████| 60/60 [00:02<00:00, 25.84it/s]
11/10/2020 14:00:51 - INFO - __main__ -   top-1 acc: 42.10
11/10/2020 14:00:51 - INFO - __main__ -   top-5 acc: 71.16
11/10/2020 14:00:51 - INFO - __main__ -   Best top-1 acc: 42.10
11/10/2020 14:00:51 - INFO - __main__ -   Mean top-1 acc: 25.36

Train Epoch: 5/ 256. Iter: 1024/1024. LR: 0.0600. Loss: 1.4380. Loss_x: 1.3406. Loss_u: 0.0974. Mask: 0.25. : 100%|██████████████████████████████████████| 1024/1024 [10:49<00:00,  1.58it/s]
Test Iter:   60/  60. Data: 0.013s. Batch: 0.034s. Loss: 2.5462. top1: 46.40. top5: 74.22. : 100%|███████████████████████████████████████████████████████████| 60/60 [00:02<00:00, 28.61it/s]
11/10/2020 14:11:43 - INFO - __main__ -   top-1 acc: 46.40
11/10/2020 14:11:43 - INFO - __main__ -   top-5 acc: 74.22
11/10/2020 14:11:43 - INFO - __main__ -   Best top-1 acc: 46.40
11/10/2020 14:11:43 - INFO - __main__ -   Mean top-1 acc: 29.57

Train Epoch: 6/ 256. Iter: 1024/1024. LR: 0.0600. Loss: 1.2794. Loss_x: 1.1647. Loss_u: 0.1147. Mask: 0.33. : 100%|██████████████████████████████████████| 1024/1024 [10:12<00:00,  1.67it/s]
Test Iter:   60/  60. Data: 0.015s. Batch: 0.036s. Loss: 2.5244. top1: 48.45. top5: 76.06. : 100%|███████████████████████████████████████████████████████████| 60/60 [00:02<00:00, 27.35it/s]
11/10/2020 14:21:58 - INFO - __main__ -   top-1 acc: 48.45
11/10/2020 14:21:58 - INFO - __main__ -   top-5 acc: 76.06
11/10/2020 14:21:58 - INFO - __main__ -   Best top-1 acc: 48.45
11/10/2020 14:21:58 - INFO - __main__ -   Mean top-1 acc: 32.72

Train Epoch: 7/ 256. Iter: 1024/1024. LR: 0.0600. Loss: 1.1613. Loss_x: 1.0336. Loss_u: 0.1277. Mask: 0.31. : 100%|██████████████████████████████████████| 1024/1024 [10:06<00:00,  1.69it/s]
Test Iter:   60/  60. Data: 0.015s. Batch: 0.036s. Loss: 2.5229. top1: 50.32. top5: 77.68. : 100%|███████████████████████████████████████████████████████████| 60/60 [00:02<00:00, 27.37it/s]
11/10/2020 14:32:07 - INFO - __main__ -   top-1 acc: 50.32
11/10/2020 14:32:07 - INFO - __main__ -   top-5 acc: 77.68
11/10/2020 14:32:07 - INFO - __main__ -   Best top-1 acc: 50.32
11/10/2020 14:32:07 - INFO - __main__ -   Mean top-1 acc: 35.23

Train Epoch: 8/ 256. Iter: 1024/1024. LR: 0.0599. Loss: 1.0700. Loss_x: 0.9330. Loss_u: 0.1370. Mask: 0.31. : 100%|██████████████████████████████████████| 1024/1024 [10:14<00:00,  1.67it/s]
Test Iter:   60/  60. Data: 0.022s. Batch: 0.045s. Loss: 2.4891. top1: 51.59. top5: 77.57. : 100%|███████████████████████████████████████████████████████████| 60/60 [00:02<00:00, 21.92it/s]
11/10/2020 14:42:24 - INFO - __main__ -   top-1 acc: 51.59
11/10/2020 14:42:24 - INFO - __main__ -   top-5 acc: 77.57
11/10/2020 14:42:24 - INFO - __main__ -   Best top-1 acc: 51.59
11/10/2020 14:42:24 - INFO - __main__ -   Mean top-1 acc: 37.28

Train Epoch: 9/ 256. Iter: 1024/1024. LR: 0.0599. Loss: 0.9960. Loss_x: 0.8518. Loss_u: 0.1442. Mask: 0.32. : 100%|██████████████████████████████████████| 1024/1024 [10:16<00:00,  1.66it/s]
Test Iter:   60/  60. Data: 0.016s. Batch: 0.038s. Loss: 2.4659. top1: 52.26. top5: 78.00. : 100%|███████████████████████████████████████████████████████████| 60/60 [00:02<00:00, 26.00it/s]
11/10/2020 14:52:43 - INFO - __main__ -   top-1 acc: 52.26
11/10/2020 14:52:43 - INFO - __main__ -   top-5 acc: 78.00
11/10/2020 14:52:43 - INFO - __main__ -   Best top-1 acc: 52.26
11/10/2020 14:52:43 - INFO - __main__ -   Mean top-1 acc: 38.94

Train Epoch: 10/ 256. Iter: 1024/1024. LR: 0.0599. Loss: 0.9362. Loss_x: 0.7862. Loss_u: 0.1500. Mask: 0.30. : 100%|█████████████████████████████████████| 1024/1024 [10:26<00:00,  1.63it/s]
Test Iter:   60/  60. Data: 0.015s. Batch: 0.036s. Loss: 2.3955. top1: 53.91. top5: 78.56. : 100%|███████████████████████████████████████████████████████████| 60/60 [00:02<00:00, 27.21it/s]
11/10/2020 15:03:12 - INFO - __main__ -   top-1 acc: 53.91
11/10/2020 15:03:12 - INFO - __main__ -   top-5 acc: 78.56
11/10/2020 15:03:12 - INFO - __main__ -   Best top-1 acc: 53.91
11/10/2020 15:03:12 - INFO - __main__ -   Mean top-1 acc: 40.44

Train Epoch: 11/ 256. Iter: 1024/1024. LR: 0.0599. Loss: 0.8863. Loss_x: 0.7313. Loss_u: 0.1549. Mask: 0.35. : 100%|█████████████████████████████████████| 1024/1024 [10:36<00:00,  1.61it/s]
Test Iter:   60/  60. Data: 0.016s. Batch: 0.037s. Loss: 2.3871. top1: 54.41. top5: 79.80. : 100%|███████████████████████████████████████████████████████████| 60/60 [00:02<00:00, 26.33it/s]
11/10/2020 15:13:51 - INFO - __main__ -   top-1 acc: 54.41
11/10/2020 15:13:51 - INFO - __main__ -   top-5 acc: 79.80
11/10/2020 15:13:51 - INFO - __main__ -   Best top-1 acc: 54.41
11/10/2020 15:13:51 - INFO - __main__ -   Mean top-1 acc: 41.71

Train Epoch: 12/ 256. Iter: 1024/1024. LR: 0.0599. Loss: 0.8433. Loss_x: 0.6844. Loss_u: 0.1588. Mask: 0.33. : 100%|█████████████████████████████████████| 1024/1024 [10:43<00:00,  1.59it/s]
Test Iter:   60/  60. Data: 0.015s. Batch: 0.037s. Loss: 2.3149. top1: 55.61. top5: 80.18. : 100%|███████████████████████████████████████████████████████████| 60/60 [00:02<00:00, 26.69it/s]
11/10/2020 15:24:37 - INFO - __main__ -   top-1 acc: 55.61
11/10/2020 15:24:37 - INFO - __main__ -   top-5 acc: 80.18
11/10/2020 15:24:37 - INFO - __main__ -   Best top-1 acc: 55.61
11/10/2020 15:24:37 - INFO - __main__ -   Mean top-1 acc: 42.87

Train Epoch: 13/ 256. Iter: 1024/1024. LR: 0.0599. Loss: 0.8088. Loss_x: 0.6465. Loss_u: 0.1622. Mask: 0.34. : 100%|█████████████████████████████████████| 1024/1024 [10:15<00:00,  1.66it/s]
Test Iter:   60/  60. Data: 0.015s. Batch: 0.036s. Loss: 2.3172. top1: 56.31. top5: 80.43. : 100%|███████████████████████████████████████████████████████████| 60/60 [00:02<00:00, 27.39it/s]
11/10/2020 15:34:54 - INFO - __main__ -   top-1 acc: 56.31
11/10/2020 15:34:54 - INFO - __main__ -   top-5 acc: 80.43
11/10/2020 15:34:55 - INFO - __main__ -   Best top-1 acc: 56.31
11/10/2020 15:34:55 - INFO - __main__ -   Mean top-1 acc: 43.90

Train Epoch: 14/ 256. Iter: 1024/1024. LR: 0.0598. Loss: 0.7758. Loss_x: 0.6111. Loss_u: 0.1647. Mask: 0.39. : 100%|█████████████████████████████████████| 1024/1024 [10:14<00:00,  1.67it/s]
Test Iter:   60/  60. Data: 0.014s. Batch: 0.034s. Loss: 2.2920. top1: 55.64. top5: 81.14. : 100%|███████████████████████████████████████████████████████████| 60/60 [00:02<00:00, 28.99it/s]
11/10/2020 15:45:11 - INFO - __main__ -   top-1 acc: 55.64
11/10/2020 15:45:11 - INFO - __main__ -   top-5 acc: 81.14
11/10/2020 15:45:11 - INFO - __main__ -   Best top-1 acc: 56.31
11/10/2020 15:45:11 - INFO - __main__ -   Mean top-1 acc: 44.74

Train Epoch: 15/ 256. Iter: 1024/1024. LR: 0.0598. Loss: 0.7479. Loss_x: 0.5808. Loss_u: 0.1671. Mask: 0.35. : 100%|█████████████████████████████████████| 1024/1024 [10:09<00:00,  1.68it/s]
Test Iter:   60/  60. Data: 0.014s. Batch: 0.035s. Loss: 2.2802. top1: 56.56. top5: 81.21. : 100%|███████████████████████████████████████████████████████████| 60/60 [00:02<00:00, 27.89it/s]
11/10/2020 15:55:22 - INFO - __main__ -   top-1 acc: 56.56
11/10/2020 15:55:22 - INFO - __main__ -   top-5 acc: 81.21
11/10/2020 15:55:23 - INFO - __main__ -   Best top-1 acc: 56.56
11/10/2020 15:55:23 - INFO - __main__ -   Mean top-1 acc: 45.53

Train Epoch: 16/ 256. Iter: 1024/1024. LR: 0.0598. Loss: 0.7241. Loss_x: 0.5548. Loss_u: 0.1693. Mask: 0.40. : 100%|█████████████████████████████████████| 1024/1024 [10:10<00:00,  1.68it/s]
Test Iter:   60/  60. Data: 0.014s. Batch: 0.035s. Loss: 2.2458. top1: 56.66. top5: 81.77. : 100%|███████████████████████████████████████████████████████████| 60/60 [00:02<00:00, 27.92it/s]
11/10/2020 16:05:35 - INFO - __main__ -   top-1 acc: 56.66
11/10/2020 16:05:35 - INFO - __main__ -   top-5 acc: 81.77
11/10/2020 16:05:35 - INFO - __main__ -   Best top-1 acc: 56.66
11/10/2020 16:05:35 - INFO - __main__ -   Mean top-1 acc: 46.22

Train Epoch: 17/ 256. Iter: 1024/1024. LR: 0.0598. Loss: 0.7025. Loss_x: 0.5316. Loss_u: 0.1709. Mask: 0.33. : 100%|█████████████████████████████████████| 1024/1024 [10:07<00:00,  1.69it/s]
Test Iter:   60/  60. Data: 0.015s. Batch: 0.036s. Loss: 2.2184. top1: 57.90. top5: 81.98. : 100%|███████████████████████████████████████████████████████████| 60/60 [00:02<00:00, 27.63it/s]
11/10/2020 16:15:45 - INFO - __main__ -   top-1 acc: 57.90
11/10/2020 16:15:45 - INFO - __main__ -   top-5 acc: 81.98
11/10/2020 16:15:45 - INFO - __main__ -   Best top-1 acc: 57.90
11/10/2020 16:15:45 - INFO - __main__ -   Mean top-1 acc: 46.91

Train Epoch: 18/ 256. Iter: 1024/1024. LR: 0.0597. Loss: 0.6822. Loss_x: 0.5099. Loss_u: 0.1723. Mask: 0.42. : 100%|█████████████████████████████████████| 1024/1024 [10:03<00:00,  1.70it/s]
Test Iter:   60/  60. Data: 0.013s. Batch: 0.035s. Loss: 2.2491. top1: 57.09. top5: 81.81. : 100%|███████████████████████████████████████████████████████████| 60/60 [00:02<00:00, 28.43it/s]
11/10/2020 16:25:51 - INFO - __main__ -   top-1 acc: 57.09
11/10/2020 16:25:51 - INFO - __main__ -   top-5 acc: 81.81
11/10/2020 16:25:51 - INFO - __main__ -   Best top-1 acc: 57.90
11/10/2020 16:25:51 - INFO - __main__ -   Mean top-1 acc: 47.47

Train Epoch: 19/ 256. Iter: 1024/1024. LR: 0.0597. Loss: 0.6638. Loss_x: 0.4904. Loss_u: 0.1734. Mask: 0.40. : 100%|█████████████████████████████████████| 1024/1024 [10:04<00:00,  1.69it/s]
Test Iter:   60/  60. Data: 0.014s. Batch: 0.035s. Loss: 2.2498. top1: 57.26. top5: 81.73. : 100%|███████████████████████████████████████████████████████████| 60/60 [00:02<00:00, 27.92it/s]
11/10/2020 16:35:58 - INFO - __main__ -   top-1 acc: 57.26
11/10/2020 16:35:58 - INFO - __main__ -   top-5 acc: 81.73
11/10/2020 16:35:58 - INFO - __main__ -   Best top-1 acc: 57.90
11/10/2020 16:35:58 - INFO - __main__ -   Mean top-1 acc: 47.99

Train Epoch: 20/ 256. Iter: 1024/1024. LR: 0.0597. Loss: 0.6477. Loss_x: 0.4730. Loss_u: 0.1747. Mask: 0.41. : 100%|█████████████████████████████████████| 1024/1024 [10:04<00:00,  1.70it/s]
Test Iter:   60/  60. Data: 0.015s. Batch: 0.036s. Loss: 2.2328. top1: 57.30. top5: 82.51. : 100%|███████████████████████████████████████████████████████████| 60/60 [00:02<00:00, 27.19it/s]
11/10/2020 16:46:04 - INFO - __main__ -   top-1 acc: 57.30
11/10/2020 16:46:04 - INFO - __main__ -   top-5 acc: 82.51
11/10/2020 16:46:04 - INFO - __main__ -   Best top-1 acc: 57.90
11/10/2020 16:46:04 - INFO - __main__ -   Mean top-1 acc: 48.46

Train Epoch: 21/ 256. Iter: 1024/1024. LR: 0.0596. Loss: 0.6331. Loss_x: 0.4573. Loss_u: 0.1759. Mask: 0.43. : 100%|█████████████████████████████████████| 1024/1024 [10:04<00:00,  1.70it/s]
Test Iter:   60/  60. Data: 0.014s. Batch: 0.035s. Loss: 2.1993. top1: 57.65. top5: 82.83. : 100%|███████████████████████████████████████████████████████████| 60/60 [00:02<00:00, 28.03it/s]
11/10/2020 16:56:10 - INFO - __main__ -   top-1 acc: 57.65
11/10/2020 16:56:10 - INFO - __main__ -   top-5 acc: 82.83
11/10/2020 16:56:10 - INFO - __main__ -   Best top-1 acc: 57.90
11/10/2020 16:56:10 - INFO - __main__ -   Mean top-1 acc: 50.87

Train Epoch: 22/ 256. Iter: 1024/1024. LR: 0.0596. Loss: 0.6201. Loss_x: 0.4429. Loss_u: 0.1772. Mask: 0.41. : 100%|█████████████████████████████████████| 1024/1024 [10:04<00:00,  1.69it/s]
Test Iter:   60/  60. Data: 0.014s. Batch: 0.034s. Loss: 2.1982. top1: 58.11. top5: 82.37. : 100%|███████████████████████████████████████████████████████████| 60/60 [00:02<00:00, 28.63it/s]
11/10/2020 17:06:17 - INFO - __main__ -   top-1 acc: 58.11
11/10/2020 17:06:17 - INFO - __main__ -   top-5 acc: 82.37
11/10/2020 17:06:17 - INFO - __main__ -   Best top-1 acc: 58.11
11/10/2020 17:06:17 - INFO - __main__ -   Mean top-1 acc: 52.88

Train Epoch: 23/ 256. Iter: 1024/1024. LR: 0.0595. Loss: 0.6072. Loss_x: 0.4291. Loss_u: 0.1781. Mask: 0.48. : 100%|█████████████████████████████████████| 1024/1024 [10:04<00:00,  1.69it/s]
Test Iter:   60/  60. Data: 0.014s. Batch: 0.036s. Loss: 2.1532. top1: 58.71. top5: 82.72. : 100%|███████████████████████████████████████████████████████████| 60/60 [00:02<00:00, 27.74it/s]
11/10/2020 17:16:24 - INFO - __main__ -   top-1 acc: 58.71
11/10/2020 17:16:24 - INFO - __main__ -   top-5 acc: 82.72
11/10/2020 17:16:24 - INFO - __main__ -   Best top-1 acc: 58.71
11/10/2020 17:16:24 - INFO - __main__ -   Mean top-1 acc: 54.21

Train Epoch: 24/ 256. Iter: 1024/1024. LR: 0.0595. Loss: 0.5965. Loss_x: 0.4176. Loss_u: 0.1789. Mask: 0.44. : 100%|█████████████████████████████████████| 1024/1024 [10:03<00:00,  1.70it/s]
Test Iter:   60/  60. Data: 0.017s. Batch: 0.038s. Loss: 2.1714. top1: 58.39. top5: 82.44. : 100%|███████████████████████████████████████████████████████████| 60/60 [00:02<00:00, 26.18it/s]
11/10/2020 17:26:30 - INFO - __main__ -   top-1 acc: 58.39
11/10/2020 17:26:30 - INFO - __main__ -   top-5 acc: 82.44
11/10/2020 17:26:30 - INFO - __main__ -   Best top-1 acc: 58.71
11/10/2020 17:26:30 - INFO - __main__ -   Mean top-1 acc: 55.03

